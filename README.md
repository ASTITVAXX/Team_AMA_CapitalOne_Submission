# Agricultural NLP Pipeline

A comprehensive Natural Language Processing pipeline designed specifically for agricultural queries in Hindi and English, with support for code-mixed text. This pipeline provides advanced language detection, text normalization, intent classification, and entity extraction capabilities.

## üåü Features

### üîç Language Detection & Normalization
- **Multi-language Support**: Detects Hindi, English, and code-mixed text
- **Advanced Detection**: Combines rule-based, statistical, and transformer-based methods
- **Text Normalization**: Converts slang and local agricultural terms to standard forms
- **Hindi to English Mapping**: Extensive dictionary of agricultural terminology

### üéØ Advanced Intent Classification
- **6 Intent Categories**:
  - `crop_advice`: Farming practices, crop diseases, cultivation techniques
  - `policy_query`: Government schemes, subsidies, policies
  - `price_query`: Market rates, crop prices, selling information
  - `weather_query`: Weather conditions, forecasts, climate information
  - `technical_support`: Equipment, technology, digital farming
  - `general_inquiry`: General agricultural information

- **Advanced Classification Methods**:
  - **Traditional ML**: TF-IDF + Naive Bayes, Logistic Regression, Random Forest
  - **Semantic Similarity**: Sentence transformers for understanding context
  - **Zero-shot Classification**: Transformer-based classification without training
  - **Ensemble Approach**: Combines multiple methods for better accuracy
  - **Learning Capability**: Can learn from new examples to improve over time

### üè∑Ô∏è Entity Extraction
- **Comprehensive Entity Types**:
  - **Crops**: Wheat, rice, maize, vegetables, fruits, cash crops
  - **Locations**: States, districts, mandis
  - **Activities**: Sowing, irrigation, harvesting, fertilizing
  - **Quantities**: Weights, areas, prices, measurements
  - **Dates**: Time references, seasons, schedules
  - **Weather**: Climate conditions, forecasts

- **Extraction Methods**:
  - Pattern-based matching
  - spaCy NER
  - Transformer-based NER

### üå§Ô∏è Weather Service
- **Historical Weather Data**: Past 20 days of comprehensive weather information
- **Weather Forecasting**: 7-day detailed weather forecast
- **Agricultural Insights**: 
  - **Soil Moisture Analysis**: Assess soil moisture levels and irrigation needs
  - **Crop Health Assessment**: Evaluate temperature and humidity stress on crops
  - **Irrigation Recommendations**: Smart irrigation scheduling based on weather
  - **Pest Risk Evaluation**: Predict pest pressure based on weather conditions
  - **Harvest Timing Optimization**: Optimal harvest timing recommendations
- **Multiple Data Sources**: Open-Meteo API (free, no API key required)
- **Location Intelligence**: Automatic geocoding and timezone detection
- **Comprehensive Reports**: Detailed weather analysis with agricultural recommendations

### üöÄ Pipeline Features
- **End-to-End Processing**: Complete query analysis in one pipeline
- **Batch Processing**: Handle multiple queries efficiently
- **Configurable**: Enable/disable components as needed
- **Performance Optimized**: Multiple processing strategies
- **Export Capabilities**: JSON and CSV output formats

## üì¶ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Install Dependencies

```bash
# Clone the repository
git clone <repository-url>
cd agricultural-nlp-pipeline

# Install Python dependencies
pip install -r requirements.txt

# Install spaCy English model
python -m spacy download en_core_web_sm
```

### Optional Dependencies
For enhanced performance with GPU support:
```bash
# Install PyTorch with CUDA support (if available)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## üöÄ Quick Start

### Basic Usage

```python
from nlp_pipeline import QueryProcessingPipeline

# Initialize the pipeline
pipeline = QueryProcessingPipeline()

# Process a single query
query = "‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§®‡•Ä ‡§ï‡§¨ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?"
result = pipeline.process_query(query)

# Access results
print(f"Primary Language: {result.primary_language}")
print(f"Primary Intent: {result.primary_intent}")
print(f"Confidence: {result.intent_confidence}")
print(f"Entities: {result.entity_summary}")
```

### Batch Processing

```python
# Process multiple queries
queries = [
    "‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§®‡•Ä ‡§ï‡§¨ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?",
    "What is the price of rice in Punjab?",
    "‡§Æ‡•Å‡§ù‡•á ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è"
]

results = pipeline.process_batch(queries)

# Get statistics
stats = pipeline.get_statistics(results)
print(f"Total queries: {stats['total_queries']}")
print(f"Average confidence: {stats['intents']['average_confidence']:.3f}")
```

### Individual Components

```python
from nlp_pipeline import LanguageDetector, TextNormalizer, AdvancedIntentClassifier, EntityExtractor

# Language Detection
detector = LanguageDetector()
scores = detector.detect_language("‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤")
print(f"Language scores: {scores}")

# Text Normalization
normalizer = TextNormalizer()
normalized = normalizer.normalize_text("‡§™‡§æ‡§®‡•Ä ‡§¶‡•á‡§®‡§æ")
print(f"Normalized: {normalized}")  # Output: "irrigate"

# Advanced Intent Classification
classifier = AdvancedIntentClassifier()
intent = classifier.get_primary_intent("How to grow wheat?")
print(f"Intent: {intent}")

# Entity Extraction
extractor = EntityExtractor()
entities = extractor.extract_entities("Wheat crop in Punjab needs irrigation")
print(f"Entities: {entities}")
```

### CLI Tools

For command-line usage:

```bash
# Interactive CLI tool
python cli.py --text "‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§®‡•Ä ‡§¶‡•á‡§®‡§æ ‡§π‡•à"
python cli.py --details  # Show detailed scores

# Weather Service CLI
python weather_cli.py --interactive  # Interactive weather service
python weather_cli.py --location "Mumbai, Maharashtra, India"  # Specific location
python weather_cli.py --location "Delhi, India" --json  # JSON output
python weather_cli.py --location "Pune, Maharashtra" --save weather_report.json  # Save to file

# Quick chatbot for single queries
python quick_chatbot.py "‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•ã‡§ó ‡§≤‡§ó ‡§ó‡§Ø‡§æ ‡§π‡•à"

# Interactive chatbot
python chatbot.py
```

## üåê API Usage

### Start the API Server

```bash
python api.py
```

The API will be available at `http://localhost:8000`

### API Endpoints

#### Process Single Query
```bash
curl -X POST "http://localhost:8000/process" \
     -H "Content-Type: application/json" \
     -d '{"text": "‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§®‡•Ä ‡§ï‡§¨ ‡§¶‡•á‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?"}'
```

#### Batch Processing
```bash
curl -X POST "http://localhost:8000/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤", "Rice price", "‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Ø‡•ã‡§ú‡§®‡§æ"]}'
```

#### Language Detection
```bash
curl -X POST "http://localhost:8000/language-detect" \
     -H "Content-Type: application/json" \
     -d '"‡§ó‡•á‡§π‡•Ç‡§Ç ‡§ï‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§™‡§æ‡§®‡•Ä ‡§¶‡•á‡§®‡§æ ‡§π‡•à"'
```

#### Intent Classification
```bash
curl -X POST "http://localhost:8000/classify-intent" \
     -H "Content-Type: application/json" \
     -d '"How to grow wheat crop?"'
```

#### Entity Extraction
```bash
curl -X POST "http://localhost:8000/extract-entities" \
     -H "Content-Type: application/json" \
     -d '"Wheat crop in Punjab needs irrigation"'
```

### API Documentation
- Interactive docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

## üå§Ô∏è Weather Service Usage

### Basic Weather Service

```python
from weather_service import WeatherService

# Initialize weather service
weather_service = WeatherService()

# Get comprehensive weather report
report = weather_service.get_comprehensive_weather_report("Mumbai, Maharashtra, India")

# Access different sections
location_info = report['location']
historical_data = report['historical_data']  # Past 20 days
forecast_data = report['forecast_data']      # Next 7 days
insights = report['agricultural_insights']   # Agricultural recommendations
```

### Individual Weather Functions

```python
# Get location coordinates
location_info = weather_service.get_location_coordinates("Delhi, India")

# Get historical weather data
historical = weather_service.get_historical_weather("Pune, Maharashtra", days=20)

# Get weather forecast
forecast = weather_service.get_weather_forecast("Bangalore, Karnataka", days=7)

# Generate agricultural insights
insights = weather_service.get_agricultural_insights(historical, forecast)
```

### Weather CLI Tool

```bash
# Interactive mode
python weather_cli.py --interactive

# Specific location with full report
python weather_cli.py --location "Mumbai, Maharashtra, India"

# JSON output for programmatic use
python weather_cli.py --location "Delhi, India" --json

# Save report to file
python weather_cli.py --location "Pune, Maharashtra" --save weather_report.json

# Specific sections only
python weather_cli.py --location "Chennai, Tamil Nadu" --historical-only
python weather_cli.py --location "Hyderabad, Telangana" --forecast-only
python weather_cli.py --location "Kolkata, West Bengal" --insights-only
```

### Weather Demo

Run the weather service demo to see all features:

```bash
python weather_demo.py
```

## üéÆ Demo & Chatbot

### Interactive Chatbot

Run the interactive chatbot for real-time query processing:

```bash
python chatbot.py
```

The chatbot provides:
- Interactive query processing
- Real-time language detection, intent classification, and entity extraction
- Processing statistics and help system
- Support for Hindi, English, and code-mixed queries

### Quick Chatbot

For quick single query processing:

```bash
python quick_chatbot.py "‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•ã‡§ó ‡§≤‡§ó ‡§ó‡§Ø‡§æ ‡§π‡•à"
python quick_chatbot.py "What is the price of rice in Punjab?"
```

### Comprehensive Demo

Run the comprehensive demo to see all features in action:

```bash
python demo.py
```

The demo includes:
- Single query processing examples
- Batch processing demonstration
- Individual component testing
- Advanced features showcase
- Performance comparison

## üìä Configuration

### Pipeline Configuration

```python
# Custom configuration
config = {
    'use_transformer': True,      # Use transformer models
    'use_spacy': True,           # Use spaCy for entity extraction
    'normalize_text': True,      # Enable text normalization
    'extract_entities': True,    # Enable entity extraction
    'classify_intent': True      # Enable intent classification
}

pipeline = QueryProcessingPipeline(**config)
result = pipeline.process_query(query, config)
```

### Component-Specific Configuration

```python
# Language detector with custom threshold
detector = LanguageDetector(use_transformer=True)
is_mixed = detector.is_code_mixed(text, threshold=0.3)

# Intent classifier with custom model path
classifier = IntentClassifier(use_transformer=True, model_path="path/to/model")

# Entity extractor with specific components
extractor = EntityExtractor(use_spacy=True, use_transformer=False)
```

## üìà Performance

### Processing Times (Average)
- **Single Query**: 0.5-2.0 seconds
- **Batch Processing**: 0.3-1.5 seconds per query
- **Language Detection**: 0.1-0.3 seconds
- **Intent Classification**: 0.2-0.8 seconds
- **Entity Extraction**: 0.3-1.0 seconds

### Accuracy Metrics
- **Language Detection**: 95%+ accuracy for Hindi/English
- **Intent Classification**: 85%+ accuracy across all intents
- **Entity Extraction**: 90%+ accuracy for agricultural entities
- **Code-mixed Detection**: 90%+ accuracy

## üîß Customization

### Adding New Intents

```python
# Extend the intent classifier
classifier = IntentClassifier()
classifier.intents['new_intent'] = {
    'description': 'Description of new intent',
    'keywords': ['keyword1', 'keyword2', '‡§ï‡•Ä‡§µ‡§∞‡•ç‡§°3']
}
```

### Adding New Entities

```python
# Extend entity patterns
extractor = EntityExtractor()
extractor.crop_entities['new_category'] = ['new_crop1', 'new_crop2']
```

### Custom Normalization

```python
# Add custom mappings
normalizer = TextNormalizer()
normalizer.hindi_to_english['custom_term'] = 'standard_term'
```

## üìÅ Project Structure

```
agricultural-nlp-pipeline/
‚îú‚îÄ‚îÄ nlp_pipeline/                    # Core NLP package
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Package initialization and exports
‚îÇ   ‚îú‚îÄ‚îÄ language_detector.py         # Multi-language detection (Hindi/English/Code-mixed)
‚îÇ   ‚îú‚îÄ‚îÄ normalizer.py                # Text normalization and slang conversion
‚îÇ   ‚îú‚îÄ‚îÄ intent_classifier.py         # Simple keyword-based intent classification
‚îÇ   ‚îú‚îÄ‚îÄ advanced_intent_classifier.py # Advanced ML-based intent classification
‚îÇ   ‚îú‚îÄ‚îÄ entity_extractor.py          # Entity extraction (crops, locations, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ pipeline.py                  # Main orchestration pipeline
‚îú‚îÄ‚îÄ chatbot.py                       # Interactive CLI chatbot
‚îú‚îÄ‚îÄ cli.py                          # Command-line interface tool
‚îú‚îÄ‚îÄ compare_classifiers.py          # Comparison between simple and advanced classifiers
‚îú‚îÄ‚îÄ requirements.txt                # Python dependencies
‚îú‚îÄ‚îÄ setup.py                        # Package installation script
‚îú‚îÄ‚îÄ install.sh                      # Automated installation script
‚îî‚îÄ‚îÄ README.md                       # This documentation
```

## üèóÔ∏è Detailed Architecture & Working Explanation

### **System Architecture Overview**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    AGRICULTURAL NLP PIPELINE                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ   INPUT     ‚îÇ    ‚îÇ  LANGUAGE   ‚îÇ    ‚îÇ   TEXT      ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ   QUERY     ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ DETECTION   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇNORMALIZATION‚îÇ         ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                   ‚îÇ               ‚îÇ
‚îÇ         ‚ñº                   ‚ñº                   ‚ñº               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ   OUTPUT    ‚îÇ    ‚îÇ   INTENT    ‚îÇ    ‚îÇ   ENTITY    ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ   RESULTS   ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇCLASSIFICATION‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÇ EXTRACTION  ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ    ‚îÇ             ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Component-Level Architecture**

#### **1. Language Detection Module** (`language_detector.py`)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Language Detector                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Rule-Based    ‚îÇ  ‚îÇ   Statistical   ‚îÇ  ‚îÇTransformer- ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Detection     ‚îÇ  ‚îÇ   Detection     ‚îÇ  ‚îÇBased        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇDetection    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Hindi patterns‚îÇ  ‚îÇ ‚Ä¢ Character     ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ English       ‚îÇ  ‚îÇ   frequency     ‚îÇ  ‚îÇ ‚Ä¢ XLM-RoBERT‚îÇ ‚îÇ
‚îÇ  ‚îÇ   patterns      ‚îÇ  ‚îÇ ‚Ä¢ N-gram        ‚îÇ  ‚îÇ ‚Ä¢ Multi-    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Code-mixed    ‚îÇ  ‚îÇ   analysis      ‚îÇ  ‚îÇ   language  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   detection     ‚îÇ  ‚îÇ ‚Ä¢ Language      ‚îÇ  ‚îÇ   support   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ   models        ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                    ‚îÇ       ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ   Ensemble      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   Decision      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                 ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Weighted      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   combination   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Confidence    ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   scoring       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Code-mixed    ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   detection     ‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **2. Text Normalization Module** (`normalizer.py`)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Text Normalizer                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Hindi NLP     ‚îÇ  ‚îÇ   English NLP   ‚îÇ  ‚îÇAgricultural ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Processing    ‚îÇ  ‚îÇ   Processing    ‚îÇ  ‚îÇTerminology  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇMapping      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Indic NLP     ‚îÇ  ‚îÇ ‚Ä¢ NLTK          ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Library       ‚îÇ  ‚îÇ   lemmatization ‚îÇ  ‚îÇ ‚Ä¢ Hindi to  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Hindi         ‚îÇ  ‚îÇ ‚Ä¢ Stop word     ‚îÇ  ‚îÇ   English   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   normalization ‚îÇ  ‚îÇ   removal       ‚îÇ  ‚îÇ   mapping   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Script        ‚îÇ  ‚îÇ ‚Ä¢ Abbreviation  ‚îÇ  ‚îÇ ‚Ä¢ Slang to  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   normalization ‚îÇ  ‚îÇ   expansion     ‚îÇ  ‚îÇ   standard  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ ‚Ä¢ Case          ‚îÇ  ‚îÇ   terms     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ   normalization ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                    ‚îÇ       ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ   Unified       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   Output        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                 ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Standardized  ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   text format   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Agricultural  ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   terminology   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Multi-        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   language      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   support       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **3. Advanced Intent Classification Module** (`advanced_intent_classifier.py`)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                Advanced Intent Classifier                   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ Traditional ML  ‚îÇ  ‚îÇ   Semantic      ‚îÇ  ‚îÇ Zero-Shot   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Classifiers   ‚îÇ  ‚îÇ   Similarity    ‚îÇ  ‚îÇClassification‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ TF-IDF + NB   ‚îÇ  ‚îÇ ‚Ä¢ Sentence      ‚îÇ  ‚îÇ ‚Ä¢ BART-Large‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ TF-IDF + LR   ‚îÇ  ‚îÇ   Transformers  ‚îÇ  ‚îÇ   MNLI      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Count + RF    ‚îÇ  ‚îÇ ‚Ä¢ Cosine        ‚îÇ  ‚îÇ ‚Ä¢ Multi-    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Ensemble      ‚îÇ  ‚îÇ   similarity    ‚îÇ  ‚îÇ   label     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   approach      ‚îÇ  ‚îÇ ‚Ä¢ Multi-metric  ‚îÇ  ‚îÇ   support   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Balanced      ‚îÇ  ‚îÇ   scoring       ‚îÇ  ‚îÇ ‚Ä¢ Hypothesis‚îÇ ‚îÇ
‚îÇ  ‚îÇ   weights       ‚îÇ  ‚îÇ ‚Ä¢ Sigmoid       ‚îÇ  ‚îÇ   templates ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ   boosting      ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                    ‚îÇ       ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              Rule-Based Fallback                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Regex patterns for each intent                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Hindi and English keyword matching                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Context-aware pattern recognition                     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Confidence boosting for strong matches                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ   Dynamic       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   Weighting     ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   System        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                 ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Adaptive      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   weights       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Confidence    ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   calibration   ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Winner        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   boosting      ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Score         ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   normalization ‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **4. Entity Extraction Module** (`entity_extractor.py`)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Entity Extractor                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ   Pattern-Based ‚îÇ  ‚îÇ   spaCy NER     ‚îÇ  ‚îÇTransformer- ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   Extraction    ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇBased NER    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Crop entities ‚îÇ  ‚îÇ ‚Ä¢ Named Entity  ‚îÇ  ‚îÇ ‚Ä¢ BERT-Base ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Location      ‚îÇ  ‚îÇ   Recognition   ‚îÇ  ‚îÇ   NER       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   entities      ‚îÇ  ‚îÇ ‚Ä¢ Agricultural  ‚îÇ  ‚îÇ ‚Ä¢ Fine-     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Activity      ‚îÇ  ‚îÇ   domain        ‚îÇ  ‚îÇ   tuned     ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   entities      ‚îÇ  ‚îÇ   adaptation    ‚îÇ  ‚îÇ   models    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Quantity      ‚îÇ  ‚îÇ ‚Ä¢ Custom        ‚îÇ  ‚îÇ ‚Ä¢ Multi-    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   entities      ‚îÇ  ‚îÇ   entity types  ‚îÇ  ‚îÇ   language  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Date/Time     ‚îÇ  ‚îÇ ‚Ä¢ Entity        ‚îÇ  ‚îÇ   support   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ   entities      ‚îÇ  ‚îÇ   linking       ‚îÇ  ‚îÇ             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ           ‚îÇ                    ‚îÇ                    ‚îÇ       ‚îÇ
‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ
‚îÇ                    ‚îÇ   Entity        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   Consolidation ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ                 ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Duplicate     ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   removal       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Confidence    ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   scoring       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Entity        ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   categorization ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ ‚Ä¢ Summary       ‚îÇ                     ‚îÇ
‚îÇ                    ‚îÇ   generation    ‚îÇ                     ‚îÇ
‚îÇ                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **5. Main Pipeline Orchestration** (`pipeline.py`)
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Query Processing Pipeline                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Input Query                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  "‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•ã‡§ó ‡§≤‡§ó ‡§ó‡§Ø‡§æ ‡§π‡•à"                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  "What is the price of rice in Punjab?"                ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                                ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                 Step 1: Language Detection              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Primary Language: Hindi/English                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Code-mixed Detection: Yes/No                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Confidence Scores: {hi: 0.85, en: 0.15}              ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                                ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                Step 2: Text Normalization               ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Original: "‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤ ‡§Æ‡•á‡§Ç ‡§∞‡•ã‡§ó ‡§≤‡§ó ‡§ó‡§Ø‡§æ ‡§π‡•à"              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Normalized: "my crop has disease problem"             ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Slang Conversion: Applied                             ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                                ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ              Step 3: Intent Classification              ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Primary Intent: crop_advice                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Confidence: 0.78                                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ All Scores: {crop_advice: 0.78, price_query: 0.12,   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                general_inquiry: 0.10}                   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                                ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                Step 4: Entity Extraction                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Crops: ["crop"]                                       ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Problems: ["disease", "problem"]                      ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Activities: []                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Locations: []                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Total Entities: 3                                     ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                ‚îÇ                            ‚îÇ
‚îÇ                                ‚ñº                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ                    Final Result                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Structured JSON output                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Processing time: 1.2 seconds                          ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Confidence metrics                                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ ‚Ä¢ Entity summaries                                      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### **Data Flow & Processing Pipeline**

#### **1. Input Processing**
```
Raw Query ‚Üí Preprocessing ‚Üí Language Detection ‚Üí Text Normalization
     ‚Üì              ‚Üì              ‚Üì                    ‚Üì
"‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤" ‚Üí "‡§Æ‡•á‡§∞‡•Ä ‡§´‡§∏‡§≤" ‚Üí Hindi (0.95) ‚Üí "my crop"
```

#### **2. Intent Classification Flow**
```
Normalized Text ‚Üí Multiple Classifiers ‚Üí Score Combination ‚Üí Final Intent
     ‚Üì                    ‚Üì                    ‚Üì              ‚Üì
"my crop" ‚Üí [ML: 0.6, Semantic: 0.7, Zero-shot: 0.5] ‚Üí 0.65 ‚Üí crop_advice
```

#### **3. Entity Extraction Flow**
```
Normalized Text ‚Üí Multiple Extractors ‚Üí Entity Consolidation ‚Üí Final Entities
     ‚Üì                    ‚Üì                    ‚Üì              ‚Üì
"my crop" ‚Üí [Pattern: crop, spaCy: CROP, BERT: CROP] ‚Üí ["crop"] ‚Üí {crops: ["crop"]}
```

### **Advanced Features & Capabilities**

#### **1. Multi-Method Intent Classification**
- **Traditional ML**: TF-IDF + Naive Bayes, Logistic Regression, Random Forest
- **Semantic Similarity**: Sentence transformers with cosine similarity
- **Zero-Shot Classification**: BART-Large MNLI for unseen intents
- **Rule-Based Fallback**: Regex patterns for reliable classification
- **Dynamic Weighting**: Adaptive weights based on method performance
- **Confidence Calibration**: Realistic confidence scoring

#### **2. Robust Language Detection**
- **Multi-language Support**: Hindi, English, and code-mixed text
- **Hybrid Approach**: Rule-based + Statistical + Transformer methods
- **Code-mixed Detection**: Identifies mixed language usage
- **Confidence Scoring**: Probabilistic language identification

#### **3. Comprehensive Entity Extraction**
- **Agricultural Entities**: Crops, locations, activities, quantities, dates
- **Multi-Extractor Approach**: Pattern-based + spaCy + Transformer NER
- **Entity Consolidation**: Removes duplicates and improves accuracy
- **Domain-Specific**: Tailored for agricultural terminology

#### **4. Intelligent Text Normalization**
- **Multi-language Processing**: Hindi and English normalization
- **Agricultural Terminology**: Domain-specific slang conversion
- **Standardization**: Consistent text format for processing
- **Preservation**: Maintains original meaning while standardizing

### **Performance Characteristics**

#### **Processing Times**
- **Language Detection**: 0.1-0.3 seconds
- **Text Normalization**: 0.05-0.1 seconds
- **Intent Classification**: 0.2-0.8 seconds
- **Entity Extraction**: 0.3-1.0 seconds
- **Total Pipeline**: 0.5-2.0 seconds

#### **Accuracy Metrics**
- **Language Detection**: 95%+ accuracy for Hindi/English
- **Intent Classification**: 85%+ accuracy across all intents
- **Entity Extraction**: 90%+ accuracy for agricultural entities
- **Code-mixed Detection**: 90%+ accuracy

#### **Confidence Scoring**
- **High Confidence**: 0.8-1.0 (üü¢ Green)
- **Medium Confidence**: 0.6-0.8 (üü° Yellow)
- **Low Confidence**: 0.0-0.6 (üî¥ Red)

### **Integration Points**

#### **1. CLI Interface** (`cli.py`)
- Command-line tool for quick testing
- Interactive mode for continuous processing
- Detailed score visualization
- Batch processing capabilities

#### **2. Interactive Chatbot** (`chatbot.py`)
- Real-time query processing
- Statistics tracking
- Help system and commands
- User-friendly interface

#### **3. API Integration** (Future)
- RESTful API endpoints
- JSON response format
- Batch processing support
- Authentication and rate limiting

### **Extensibility & Customization**

#### **1. Adding New Intents**
```python
classifier.intents['new_intent'] = {
    'description': 'Description of new intent',
    'examples': ['example1', 'example2', 'example3']
}
```

#### **2. Adding New Entities**
```python
extractor.crop_entities['new_category'] = ['new_crop1', 'new_crop2']
```

#### **3. Custom Normalization**
```python
normalizer.hindi_to_english['custom_term'] = 'standard_term'
```

This comprehensive architecture ensures robust, accurate, and scalable agricultural query processing with support for multiple languages and advanced NLP techniques.

## ü§ù Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìù License

This project is licensed under the IIT Kanpur

## üôè Acknowledgments

- **Transformers**: Hugging Face for pre-trained models
- **spaCy**: Industrial-strength NLP library
- **Indic NLP Library**: For Hindi text processing
- **Agricultural Domain Experts**: For terminology and validation

## üìû Support

For questions, issues, or contributions:
- Create an issue on GitHub
- Contact the development team
- Check the documentation at `/docs` when running the API

## üîÑ Updates

### Version 1.0.0
- Initial release with core NLP pipeline
- Support for Hindi/English/code-mixed text
- Complete intent classification system
- Comprehensive entity extraction
- REST API with FastAPI
- Comprehensive demo and documentation
